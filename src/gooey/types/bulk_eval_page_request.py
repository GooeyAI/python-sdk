# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing

from ..core.datetime_utils import serialize_datetime
from ..core.pydantic_utilities import deep_union_pydantic_dicts, pydantic_v1
from .agg_function import AggFunction
from .bulk_eval_page_request_selected_model import BulkEvalPageRequestSelectedModel
from .eval_prompt import EvalPrompt
from .recipe_function import RecipeFunction
from .run_settings import RunSettings


class BulkEvalPageRequest(pydantic_v1.BaseModel):
    functions: typing.Optional[typing.List[RecipeFunction]] = None
    variables: typing.Optional[typing.Dict[str, typing.Any]] = pydantic_v1.Field(default=None)
    """
    Variables to be used as Jinja prompt templates and in functions as arguments
    """

    selected_model: typing.Optional[BulkEvalPageRequestSelectedModel] = None
    avoid_repetition: typing.Optional[bool] = None
    num_outputs: typing.Optional[int] = None
    quality: typing.Optional[float] = None
    max_tokens: typing.Optional[int] = None
    sampling_temperature: typing.Optional[float] = None
    documents: typing.List[str] = pydantic_v1.Field()
    """
    Upload or link to a CSV or google sheet that contains your sample input data.
    For example, for Copilot, this would sample questions or for Art QR Code, would would be pairs of image descriptions and URLs.
    Remember to includes header names in your CSV too.
    """

    eval_prompts: typing.Optional[typing.List[EvalPrompt]] = pydantic_v1.Field(default=None)
    """
    Specify custom LLM prompts to calculate metrics that evaluate each row of the input data. The output should be a JSON object mapping the metric names to values.  
    _The `columns` dictionary can be used to reference the spreadsheet columns._  
    """

    agg_functions: typing.Optional[typing.List[AggFunction]] = pydantic_v1.Field(default=None)
    """
    Aggregate using one or more operations. Uses [pandas](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html#dataframegroupby-computations-descriptive-stats).
    """

    settings: typing.Optional[RunSettings] = None

    def json(self, **kwargs: typing.Any) -> str:
        kwargs_with_defaults: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        return super().json(**kwargs_with_defaults)

    def dict(self, **kwargs: typing.Any) -> typing.Dict[str, typing.Any]:
        kwargs_with_defaults_exclude_unset: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        kwargs_with_defaults_exclude_none: typing.Any = {"by_alias": True, "exclude_none": True, **kwargs}

        return deep_union_pydantic_dicts(
            super().dict(**kwargs_with_defaults_exclude_unset), super().dict(**kwargs_with_defaults_exclude_none)
        )

    class Config:
        frozen = True
        smart_union = True
        extra = pydantic_v1.Extra.allow
        json_encoders = {dt.datetime: serialize_datetime}
