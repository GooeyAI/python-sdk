# This file was auto-generated by Fern from our API Definition.

import typing
from json.decoder import JSONDecodeError

from ..core.api_error import ApiError
from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.jsonable_encoder import jsonable_encoder
from ..core.pydantic_utilities import parse_obj_as
from ..core.request_options import RequestOptions
from ..errors.payment_required_error import PaymentRequiredError
from ..errors.unprocessable_entity_error import UnprocessableEntityError
from ..types.button_pressed import ButtonPressed
from ..types.conversation_entry import ConversationEntry
from ..types.create_stream_response import CreateStreamResponse
from ..types.http_validation_error import HttpValidationError
from ..types.llm_tools import LlmTools
from ..types.recipe_function import RecipeFunction
from ..types.sad_talker_settings import SadTalkerSettings
from .types.video_bots_stream_create_request_asr_model import VideoBotsStreamCreateRequestAsrModel
from .types.video_bots_stream_create_request_citation_style import VideoBotsStreamCreateRequestCitationStyle
from .types.video_bots_stream_create_request_embedding_model import VideoBotsStreamCreateRequestEmbeddingModel
from .types.video_bots_stream_create_request_lipsync_model import VideoBotsStreamCreateRequestLipsyncModel
from .types.video_bots_stream_create_request_openai_tts_model import VideoBotsStreamCreateRequestOpenaiTtsModel
from .types.video_bots_stream_create_request_openai_voice_name import VideoBotsStreamCreateRequestOpenaiVoiceName
from .types.video_bots_stream_create_request_response_format_type import VideoBotsStreamCreateRequestResponseFormatType
from .types.video_bots_stream_create_request_selected_model import VideoBotsStreamCreateRequestSelectedModel
from .types.video_bots_stream_create_request_translation_model import VideoBotsStreamCreateRequestTranslationModel
from .types.video_bots_stream_create_request_tts_provider import VideoBotsStreamCreateRequestTtsProvider
from .types.video_bots_stream_response import VideoBotsStreamResponse

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class CopilotIntegrationsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def video_bots_stream_create(
        self,
        *,
        integration_id: str,
        conversation_id: typing.Optional[str] = None,
        user_id: typing.Optional[str] = None,
        user_message_id: typing.Optional[str] = None,
        button_pressed: typing.Optional[ButtonPressed] = None,
        functions: typing.Optional[typing.List[RecipeFunction]] = None,
        variables: typing.Optional[typing.Dict[str, typing.Any]] = None,
        input_prompt: typing.Optional[str] = None,
        input_audio: typing.Optional[str] = None,
        input_images: typing.Optional[typing.List[str]] = None,
        input_documents: typing.Optional[typing.List[str]] = None,
        doc_extract_url: typing.Optional[str] = None,
        messages: typing.Optional[typing.List[ConversationEntry]] = None,
        bot_script: typing.Optional[str] = None,
        selected_model: typing.Optional[VideoBotsStreamCreateRequestSelectedModel] = None,
        document_model: typing.Optional[str] = None,
        task_instructions: typing.Optional[str] = None,
        query_instructions: typing.Optional[str] = None,
        keyword_instructions: typing.Optional[str] = None,
        documents: typing.Optional[typing.List[str]] = None,
        max_references: typing.Optional[int] = None,
        max_context_words: typing.Optional[int] = None,
        scroll_jump: typing.Optional[int] = None,
        embedding_model: typing.Optional[VideoBotsStreamCreateRequestEmbeddingModel] = None,
        dense_weight: typing.Optional[float] = None,
        citation_style: typing.Optional[VideoBotsStreamCreateRequestCitationStyle] = None,
        use_url_shortener: typing.Optional[bool] = None,
        asr_model: typing.Optional[VideoBotsStreamCreateRequestAsrModel] = None,
        asr_language: typing.Optional[str] = None,
        translation_model: typing.Optional[VideoBotsStreamCreateRequestTranslationModel] = None,
        user_language: typing.Optional[str] = None,
        input_glossary_document: typing.Optional[str] = None,
        output_glossary_document: typing.Optional[str] = None,
        lipsync_model: typing.Optional[VideoBotsStreamCreateRequestLipsyncModel] = None,
        tools: typing.Optional[typing.List[LlmTools]] = None,
        avoid_repetition: typing.Optional[bool] = None,
        num_outputs: typing.Optional[int] = None,
        quality: typing.Optional[float] = None,
        max_tokens: typing.Optional[int] = None,
        sampling_temperature: typing.Optional[float] = None,
        response_format_type: typing.Optional[VideoBotsStreamCreateRequestResponseFormatType] = None,
        tts_provider: typing.Optional[VideoBotsStreamCreateRequestTtsProvider] = None,
        uberduck_voice_name: typing.Optional[str] = None,
        uberduck_speaking_rate: typing.Optional[float] = None,
        google_voice_name: typing.Optional[str] = None,
        google_speaking_rate: typing.Optional[float] = None,
        google_pitch: typing.Optional[float] = None,
        bark_history_prompt: typing.Optional[str] = None,
        elevenlabs_voice_name: typing.Optional[str] = None,
        elevenlabs_api_key: typing.Optional[str] = None,
        elevenlabs_voice_id: typing.Optional[str] = None,
        elevenlabs_model: typing.Optional[str] = None,
        elevenlabs_stability: typing.Optional[float] = None,
        elevenlabs_similarity_boost: typing.Optional[float] = None,
        elevenlabs_style: typing.Optional[float] = None,
        elevenlabs_speaker_boost: typing.Optional[bool] = None,
        azure_voice_name: typing.Optional[str] = None,
        openai_voice_name: typing.Optional[VideoBotsStreamCreateRequestOpenaiVoiceName] = None,
        openai_tts_model: typing.Optional[VideoBotsStreamCreateRequestOpenaiTtsModel] = None,
        input_face: typing.Optional[str] = None,
        face_padding_top: typing.Optional[int] = None,
        face_padding_bottom: typing.Optional[int] = None,
        face_padding_left: typing.Optional[int] = None,
        face_padding_right: typing.Optional[int] = None,
        sadtalker_settings: typing.Optional[SadTalkerSettings] = None,
        input_text: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> CreateStreamResponse:
        """
        Parameters
        ----------
        integration_id : str
            Your Integration ID as shown in the Copilot Integrations tab

        conversation_id : typing.Optional[str]
            The gooey conversation ID.

            If not provided, a new conversation will be started and a new ID will be returned in the response. Use this to maintain the state of the conversation between requests.

            Note that you may not provide a custom ID here, and must only use the `conversation_id` returned in a previous response.

        user_id : typing.Optional[str]
            Your app's custom user ID.

            If not provided, a random user will be created and a new ID will be returned in the response. If a `conversation_id` is provided, this field is automatically set to the user's id associated with that conversation.

        user_message_id : typing.Optional[str]
            Your app's custom message ID for the user message.

            If not provided, a random ID will be generated and returned in the response. This is useful for tracking messages in the conversation.

        button_pressed : typing.Optional[ButtonPressed]
            The button that was pressed by the user.

        functions : typing.Optional[typing.List[RecipeFunction]]

        variables : typing.Optional[typing.Dict[str, typing.Any]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        input_prompt : typing.Optional[str]

        input_audio : typing.Optional[str]

        input_images : typing.Optional[typing.List[str]]

        input_documents : typing.Optional[typing.List[str]]

        doc_extract_url : typing.Optional[str]
            Select a workflow to extract text from documents and images.

        messages : typing.Optional[typing.List[ConversationEntry]]

        bot_script : typing.Optional[str]

        selected_model : typing.Optional[VideoBotsStreamCreateRequestSelectedModel]

        document_model : typing.Optional[str]
            When your copilot users upload a photo or pdf, what kind of document are they mostly likely to upload? (via [Azure](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/use-sdk-rest-api?view=doc-intel-3.1.0&tabs=linux&pivots=programming-language-rest-api))

        task_instructions : typing.Optional[str]

        query_instructions : typing.Optional[str]

        keyword_instructions : typing.Optional[str]

        documents : typing.Optional[typing.List[str]]

        max_references : typing.Optional[int]

        max_context_words : typing.Optional[int]

        scroll_jump : typing.Optional[int]

        embedding_model : typing.Optional[VideoBotsStreamCreateRequestEmbeddingModel]

        dense_weight : typing.Optional[float]

            Weightage for dense vs sparse embeddings. `0` for sparse, `1` for dense, `0.5` for equal weight.
            Generally speaking, dense embeddings excel at understanding the context of the query, whereas sparse vectors excel at keyword matches.


        citation_style : typing.Optional[VideoBotsStreamCreateRequestCitationStyle]

        use_url_shortener : typing.Optional[bool]

        asr_model : typing.Optional[VideoBotsStreamCreateRequestAsrModel]
            Choose a model to transcribe incoming audio messages to text.

        asr_language : typing.Optional[str]
            Choose a language to transcribe incoming audio messages to text.

        translation_model : typing.Optional[VideoBotsStreamCreateRequestTranslationModel]

        user_language : typing.Optional[str]
            Choose a language to translate incoming text & audio messages to English and responses back to your selected language. Useful for low-resource languages.

        input_glossary_document : typing.Optional[str]

            Translation Glossary for User Langauge -> LLM Language (English)


        output_glossary_document : typing.Optional[str]

            Translation Glossary for LLM Language (English) -> User Langauge


        lipsync_model : typing.Optional[VideoBotsStreamCreateRequestLipsyncModel]

        tools : typing.Optional[typing.List[LlmTools]]
            Give your copilot superpowers by giving it access to tools. Powered by [Function calling](https://platform.openai.com/docs/guides/function-calling).

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[VideoBotsStreamCreateRequestResponseFormatType]

        tts_provider : typing.Optional[VideoBotsStreamCreateRequestTtsProvider]

        uberduck_voice_name : typing.Optional[str]

        uberduck_speaking_rate : typing.Optional[float]

        google_voice_name : typing.Optional[str]

        google_speaking_rate : typing.Optional[float]

        google_pitch : typing.Optional[float]

        bark_history_prompt : typing.Optional[str]

        elevenlabs_voice_name : typing.Optional[str]
            Use `elevenlabs_voice_id` instead

        elevenlabs_api_key : typing.Optional[str]

        elevenlabs_voice_id : typing.Optional[str]

        elevenlabs_model : typing.Optional[str]

        elevenlabs_stability : typing.Optional[float]

        elevenlabs_similarity_boost : typing.Optional[float]

        elevenlabs_style : typing.Optional[float]

        elevenlabs_speaker_boost : typing.Optional[bool]

        azure_voice_name : typing.Optional[str]

        openai_voice_name : typing.Optional[VideoBotsStreamCreateRequestOpenaiVoiceName]

        openai_tts_model : typing.Optional[VideoBotsStreamCreateRequestOpenaiTtsModel]

        input_face : typing.Optional[str]

        face_padding_top : typing.Optional[int]

        face_padding_bottom : typing.Optional[int]

        face_padding_left : typing.Optional[int]

        face_padding_right : typing.Optional[int]

        sadtalker_settings : typing.Optional[SadTalkerSettings]

        input_text : typing.Optional[str]
            Use `input_prompt` instead

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        CreateStreamResponse
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.copilot_integrations.video_bots_stream_create(
            integration_id="integration_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v3/integrations/stream",
            method="POST",
            data={
                "integration_id": integration_id,
                "conversation_id": conversation_id,
                "user_id": user_id,
                "user_message_id": user_message_id,
                "button_pressed": button_pressed,
                "functions": functions,
                "variables": variables,
                "input_prompt": input_prompt,
                "input_audio": input_audio,
                "input_images": input_images,
                "input_documents": input_documents,
                "doc_extract_url": doc_extract_url,
                "messages": messages,
                "bot_script": bot_script,
                "selected_model": selected_model,
                "document_model": document_model,
                "task_instructions": task_instructions,
                "query_instructions": query_instructions,
                "keyword_instructions": keyword_instructions,
                "documents": documents,
                "max_references": max_references,
                "max_context_words": max_context_words,
                "scroll_jump": scroll_jump,
                "embedding_model": embedding_model,
                "dense_weight": dense_weight,
                "citation_style": citation_style,
                "use_url_shortener": use_url_shortener,
                "asr_model": asr_model,
                "asr_language": asr_language,
                "translation_model": translation_model,
                "user_language": user_language,
                "input_glossary_document": input_glossary_document,
                "output_glossary_document": output_glossary_document,
                "lipsync_model": lipsync_model,
                "tools": tools,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "tts_provider": tts_provider,
                "uberduck_voice_name": uberduck_voice_name,
                "uberduck_speaking_rate": uberduck_speaking_rate,
                "google_voice_name": google_voice_name,
                "google_speaking_rate": google_speaking_rate,
                "google_pitch": google_pitch,
                "bark_history_prompt": bark_history_prompt,
                "elevenlabs_voice_name": elevenlabs_voice_name,
                "elevenlabs_api_key": elevenlabs_api_key,
                "elevenlabs_voice_id": elevenlabs_voice_id,
                "elevenlabs_model": elevenlabs_model,
                "elevenlabs_stability": elevenlabs_stability,
                "elevenlabs_similarity_boost": elevenlabs_similarity_boost,
                "elevenlabs_style": elevenlabs_style,
                "elevenlabs_speaker_boost": elevenlabs_speaker_boost,
                "azure_voice_name": azure_voice_name,
                "openai_voice_name": openai_voice_name,
                "openai_tts_model": openai_tts_model,
                "input_face": input_face,
                "face_padding_top": face_padding_top,
                "face_padding_bottom": face_padding_bottom,
                "face_padding_left": face_padding_left,
                "face_padding_right": face_padding_right,
                "sadtalker_settings": sadtalker_settings,
                "input_text": input_text,
            },
            files={},
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(CreateStreamResponse, parse_obj_as(type_=CreateStreamResponse, object_=_response.json()))  # type: ignore
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(typing.Any, parse_obj_as(type_=typing.Any, object_=_response.json()))  # type: ignore
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(HttpValidationError, parse_obj_as(type_=HttpValidationError, object_=_response.json()))  # type: ignore
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def video_bots_stream(
        self, request_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> VideoBotsStreamResponse:
        """
        Parameters
        ----------
        request_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        VideoBotsStreamResponse
            Successful Response

        Examples
        --------
        from gooey import Gooey

        client = Gooey(
            api_key="YOUR_API_KEY",
        )
        client.copilot_integrations.video_bots_stream(
            request_id="request_id",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            f"v3/integrations/stream/{jsonable_encoder(request_id)}", method="GET", request_options=request_options
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(VideoBotsStreamResponse, parse_obj_as(type_=VideoBotsStreamResponse, object_=_response.json()))  # type: ignore
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(typing.Any, parse_obj_as(type_=typing.Any, object_=_response.json()))  # type: ignore
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(HttpValidationError, parse_obj_as(type_=HttpValidationError, object_=_response.json()))  # type: ignore
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncCopilotIntegrationsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def video_bots_stream_create(
        self,
        *,
        integration_id: str,
        conversation_id: typing.Optional[str] = None,
        user_id: typing.Optional[str] = None,
        user_message_id: typing.Optional[str] = None,
        button_pressed: typing.Optional[ButtonPressed] = None,
        functions: typing.Optional[typing.List[RecipeFunction]] = None,
        variables: typing.Optional[typing.Dict[str, typing.Any]] = None,
        input_prompt: typing.Optional[str] = None,
        input_audio: typing.Optional[str] = None,
        input_images: typing.Optional[typing.List[str]] = None,
        input_documents: typing.Optional[typing.List[str]] = None,
        doc_extract_url: typing.Optional[str] = None,
        messages: typing.Optional[typing.List[ConversationEntry]] = None,
        bot_script: typing.Optional[str] = None,
        selected_model: typing.Optional[VideoBotsStreamCreateRequestSelectedModel] = None,
        document_model: typing.Optional[str] = None,
        task_instructions: typing.Optional[str] = None,
        query_instructions: typing.Optional[str] = None,
        keyword_instructions: typing.Optional[str] = None,
        documents: typing.Optional[typing.List[str]] = None,
        max_references: typing.Optional[int] = None,
        max_context_words: typing.Optional[int] = None,
        scroll_jump: typing.Optional[int] = None,
        embedding_model: typing.Optional[VideoBotsStreamCreateRequestEmbeddingModel] = None,
        dense_weight: typing.Optional[float] = None,
        citation_style: typing.Optional[VideoBotsStreamCreateRequestCitationStyle] = None,
        use_url_shortener: typing.Optional[bool] = None,
        asr_model: typing.Optional[VideoBotsStreamCreateRequestAsrModel] = None,
        asr_language: typing.Optional[str] = None,
        translation_model: typing.Optional[VideoBotsStreamCreateRequestTranslationModel] = None,
        user_language: typing.Optional[str] = None,
        input_glossary_document: typing.Optional[str] = None,
        output_glossary_document: typing.Optional[str] = None,
        lipsync_model: typing.Optional[VideoBotsStreamCreateRequestLipsyncModel] = None,
        tools: typing.Optional[typing.List[LlmTools]] = None,
        avoid_repetition: typing.Optional[bool] = None,
        num_outputs: typing.Optional[int] = None,
        quality: typing.Optional[float] = None,
        max_tokens: typing.Optional[int] = None,
        sampling_temperature: typing.Optional[float] = None,
        response_format_type: typing.Optional[VideoBotsStreamCreateRequestResponseFormatType] = None,
        tts_provider: typing.Optional[VideoBotsStreamCreateRequestTtsProvider] = None,
        uberduck_voice_name: typing.Optional[str] = None,
        uberduck_speaking_rate: typing.Optional[float] = None,
        google_voice_name: typing.Optional[str] = None,
        google_speaking_rate: typing.Optional[float] = None,
        google_pitch: typing.Optional[float] = None,
        bark_history_prompt: typing.Optional[str] = None,
        elevenlabs_voice_name: typing.Optional[str] = None,
        elevenlabs_api_key: typing.Optional[str] = None,
        elevenlabs_voice_id: typing.Optional[str] = None,
        elevenlabs_model: typing.Optional[str] = None,
        elevenlabs_stability: typing.Optional[float] = None,
        elevenlabs_similarity_boost: typing.Optional[float] = None,
        elevenlabs_style: typing.Optional[float] = None,
        elevenlabs_speaker_boost: typing.Optional[bool] = None,
        azure_voice_name: typing.Optional[str] = None,
        openai_voice_name: typing.Optional[VideoBotsStreamCreateRequestOpenaiVoiceName] = None,
        openai_tts_model: typing.Optional[VideoBotsStreamCreateRequestOpenaiTtsModel] = None,
        input_face: typing.Optional[str] = None,
        face_padding_top: typing.Optional[int] = None,
        face_padding_bottom: typing.Optional[int] = None,
        face_padding_left: typing.Optional[int] = None,
        face_padding_right: typing.Optional[int] = None,
        sadtalker_settings: typing.Optional[SadTalkerSettings] = None,
        input_text: typing.Optional[str] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> CreateStreamResponse:
        """
        Parameters
        ----------
        integration_id : str
            Your Integration ID as shown in the Copilot Integrations tab

        conversation_id : typing.Optional[str]
            The gooey conversation ID.

            If not provided, a new conversation will be started and a new ID will be returned in the response. Use this to maintain the state of the conversation between requests.

            Note that you may not provide a custom ID here, and must only use the `conversation_id` returned in a previous response.

        user_id : typing.Optional[str]
            Your app's custom user ID.

            If not provided, a random user will be created and a new ID will be returned in the response. If a `conversation_id` is provided, this field is automatically set to the user's id associated with that conversation.

        user_message_id : typing.Optional[str]
            Your app's custom message ID for the user message.

            If not provided, a random ID will be generated and returned in the response. This is useful for tracking messages in the conversation.

        button_pressed : typing.Optional[ButtonPressed]
            The button that was pressed by the user.

        functions : typing.Optional[typing.List[RecipeFunction]]

        variables : typing.Optional[typing.Dict[str, typing.Any]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        input_prompt : typing.Optional[str]

        input_audio : typing.Optional[str]

        input_images : typing.Optional[typing.List[str]]

        input_documents : typing.Optional[typing.List[str]]

        doc_extract_url : typing.Optional[str]
            Select a workflow to extract text from documents and images.

        messages : typing.Optional[typing.List[ConversationEntry]]

        bot_script : typing.Optional[str]

        selected_model : typing.Optional[VideoBotsStreamCreateRequestSelectedModel]

        document_model : typing.Optional[str]
            When your copilot users upload a photo or pdf, what kind of document are they mostly likely to upload? (via [Azure](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/use-sdk-rest-api?view=doc-intel-3.1.0&tabs=linux&pivots=programming-language-rest-api))

        task_instructions : typing.Optional[str]

        query_instructions : typing.Optional[str]

        keyword_instructions : typing.Optional[str]

        documents : typing.Optional[typing.List[str]]

        max_references : typing.Optional[int]

        max_context_words : typing.Optional[int]

        scroll_jump : typing.Optional[int]

        embedding_model : typing.Optional[VideoBotsStreamCreateRequestEmbeddingModel]

        dense_weight : typing.Optional[float]

            Weightage for dense vs sparse embeddings. `0` for sparse, `1` for dense, `0.5` for equal weight.
            Generally speaking, dense embeddings excel at understanding the context of the query, whereas sparse vectors excel at keyword matches.


        citation_style : typing.Optional[VideoBotsStreamCreateRequestCitationStyle]

        use_url_shortener : typing.Optional[bool]

        asr_model : typing.Optional[VideoBotsStreamCreateRequestAsrModel]
            Choose a model to transcribe incoming audio messages to text.

        asr_language : typing.Optional[str]
            Choose a language to transcribe incoming audio messages to text.

        translation_model : typing.Optional[VideoBotsStreamCreateRequestTranslationModel]

        user_language : typing.Optional[str]
            Choose a language to translate incoming text & audio messages to English and responses back to your selected language. Useful for low-resource languages.

        input_glossary_document : typing.Optional[str]

            Translation Glossary for User Langauge -> LLM Language (English)


        output_glossary_document : typing.Optional[str]

            Translation Glossary for LLM Language (English) -> User Langauge


        lipsync_model : typing.Optional[VideoBotsStreamCreateRequestLipsyncModel]

        tools : typing.Optional[typing.List[LlmTools]]
            Give your copilot superpowers by giving it access to tools. Powered by [Function calling](https://platform.openai.com/docs/guides/function-calling).

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        response_format_type : typing.Optional[VideoBotsStreamCreateRequestResponseFormatType]

        tts_provider : typing.Optional[VideoBotsStreamCreateRequestTtsProvider]

        uberduck_voice_name : typing.Optional[str]

        uberduck_speaking_rate : typing.Optional[float]

        google_voice_name : typing.Optional[str]

        google_speaking_rate : typing.Optional[float]

        google_pitch : typing.Optional[float]

        bark_history_prompt : typing.Optional[str]

        elevenlabs_voice_name : typing.Optional[str]
            Use `elevenlabs_voice_id` instead

        elevenlabs_api_key : typing.Optional[str]

        elevenlabs_voice_id : typing.Optional[str]

        elevenlabs_model : typing.Optional[str]

        elevenlabs_stability : typing.Optional[float]

        elevenlabs_similarity_boost : typing.Optional[float]

        elevenlabs_style : typing.Optional[float]

        elevenlabs_speaker_boost : typing.Optional[bool]

        azure_voice_name : typing.Optional[str]

        openai_voice_name : typing.Optional[VideoBotsStreamCreateRequestOpenaiVoiceName]

        openai_tts_model : typing.Optional[VideoBotsStreamCreateRequestOpenaiTtsModel]

        input_face : typing.Optional[str]

        face_padding_top : typing.Optional[int]

        face_padding_bottom : typing.Optional[int]

        face_padding_left : typing.Optional[int]

        face_padding_right : typing.Optional[int]

        sadtalker_settings : typing.Optional[SadTalkerSettings]

        input_text : typing.Optional[str]
            Use `input_prompt` instead

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        CreateStreamResponse
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.copilot_integrations.video_bots_stream_create(
                integration_id="integration_id",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v3/integrations/stream",
            method="POST",
            data={
                "integration_id": integration_id,
                "conversation_id": conversation_id,
                "user_id": user_id,
                "user_message_id": user_message_id,
                "button_pressed": button_pressed,
                "functions": functions,
                "variables": variables,
                "input_prompt": input_prompt,
                "input_audio": input_audio,
                "input_images": input_images,
                "input_documents": input_documents,
                "doc_extract_url": doc_extract_url,
                "messages": messages,
                "bot_script": bot_script,
                "selected_model": selected_model,
                "document_model": document_model,
                "task_instructions": task_instructions,
                "query_instructions": query_instructions,
                "keyword_instructions": keyword_instructions,
                "documents": documents,
                "max_references": max_references,
                "max_context_words": max_context_words,
                "scroll_jump": scroll_jump,
                "embedding_model": embedding_model,
                "dense_weight": dense_weight,
                "citation_style": citation_style,
                "use_url_shortener": use_url_shortener,
                "asr_model": asr_model,
                "asr_language": asr_language,
                "translation_model": translation_model,
                "user_language": user_language,
                "input_glossary_document": input_glossary_document,
                "output_glossary_document": output_glossary_document,
                "lipsync_model": lipsync_model,
                "tools": tools,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "response_format_type": response_format_type,
                "tts_provider": tts_provider,
                "uberduck_voice_name": uberduck_voice_name,
                "uberduck_speaking_rate": uberduck_speaking_rate,
                "google_voice_name": google_voice_name,
                "google_speaking_rate": google_speaking_rate,
                "google_pitch": google_pitch,
                "bark_history_prompt": bark_history_prompt,
                "elevenlabs_voice_name": elevenlabs_voice_name,
                "elevenlabs_api_key": elevenlabs_api_key,
                "elevenlabs_voice_id": elevenlabs_voice_id,
                "elevenlabs_model": elevenlabs_model,
                "elevenlabs_stability": elevenlabs_stability,
                "elevenlabs_similarity_boost": elevenlabs_similarity_boost,
                "elevenlabs_style": elevenlabs_style,
                "elevenlabs_speaker_boost": elevenlabs_speaker_boost,
                "azure_voice_name": azure_voice_name,
                "openai_voice_name": openai_voice_name,
                "openai_tts_model": openai_tts_model,
                "input_face": input_face,
                "face_padding_top": face_padding_top,
                "face_padding_bottom": face_padding_bottom,
                "face_padding_left": face_padding_left,
                "face_padding_right": face_padding_right,
                "sadtalker_settings": sadtalker_settings,
                "input_text": input_text,
            },
            files={},
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(CreateStreamResponse, parse_obj_as(type_=CreateStreamResponse, object_=_response.json()))  # type: ignore
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(typing.Any, parse_obj_as(type_=typing.Any, object_=_response.json()))  # type: ignore
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(HttpValidationError, parse_obj_as(type_=HttpValidationError, object_=_response.json()))  # type: ignore
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def video_bots_stream(
        self, request_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> VideoBotsStreamResponse:
        """
        Parameters
        ----------
        request_id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        VideoBotsStreamResponse
            Successful Response

        Examples
        --------
        import asyncio

        from gooey import AsyncGooey

        client = AsyncGooey(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.copilot_integrations.video_bots_stream(
                request_id="request_id",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"v3/integrations/stream/{jsonable_encoder(request_id)}", method="GET", request_options=request_options
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(VideoBotsStreamResponse, parse_obj_as(type_=VideoBotsStreamResponse, object_=_response.json()))  # type: ignore
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(typing.Any, parse_obj_as(type_=typing.Any, object_=_response.json()))  # type: ignore
                )
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    typing.cast(HttpValidationError, parse_obj_as(type_=HttpValidationError, object_=_response.json()))  # type: ignore
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
