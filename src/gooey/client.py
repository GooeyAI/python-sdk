# This file was auto-generated by Fern from our API Definition.

import typing
from json.decoder import JSONDecodeError

import httpx

from .ai_animation_generator.client import AiAnimationGeneratorClient, AsyncAiAnimationGeneratorClient
from .ai_art_qr_code.client import AiArtQrCodeClient, AsyncAiArtQrCodeClient
from .ai_background_changer.client import AiBackgroundChangerClient, AsyncAiBackgroundChangerClient
from .ai_generated_photo_from_email_profile_lookup.client import (
    AiGeneratedPhotoFromEmailProfileLookupClient,
    AsyncAiGeneratedPhotoFromEmailProfileLookupClient,
)
from .ai_image_with_a_face.client import AiImageWithAFaceClient, AsyncAiImageWithAFaceClient
from .bulk_runner.client import AsyncBulkRunnerClient, BulkRunnerClient
from .chyron_plant_bot.client import AsyncChyronPlantBotClient, ChyronPlantBotClient
from .compare_ai_image_generators.client import AsyncCompareAiImageGeneratorsClient, CompareAiImageGeneratorsClient
from .compare_ai_image_upscalers.client import AsyncCompareAiImageUpscalersClient, CompareAiImageUpscalersClient
from .compare_ai_translations.client import AsyncCompareAiTranslationsClient, CompareAiTranslationsClient
from .compare_ai_voice_generators.client import AsyncCompareAiVoiceGeneratorsClient, CompareAiVoiceGeneratorsClient
from .copilot_for_your_enterprise.client import AsyncCopilotForYourEnterpriseClient, CopilotForYourEnterpriseClient
from .copilot_integrations.client import AsyncCopilotIntegrationsClient, CopilotIntegrationsClient
from .core.api_error import ApiError
from .core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from .core.pydantic_utilities import pydantic_v1
from .core.request_options import RequestOptions
from .create_a_perfect_seo_optimized_title_paragraph.client import (
    AsyncCreateAPerfectSeoOptimizedTitleParagraphClient,
    CreateAPerfectSeoOptimizedTitleParagraphClient,
)
from .edit_an_image_with_ai_prompt.client import AsyncEditAnImageWithAiPromptClient, EditAnImageWithAiPromptClient
from .embeddings.client import AsyncEmbeddingsClient, EmbeddingsClient
from .errors.internal_server_error import InternalServerError
from .errors.payment_required_error import PaymentRequiredError
from .errors.too_many_requests_error import TooManyRequestsError
from .errors.unprocessable_entity_error import UnprocessableEntityError
from .evaluator.client import AsyncEvaluatorClient, EvaluatorClient
from .functions.client import AsyncFunctionsClient, FunctionsClient
from .generate_people_also_ask_seo_content.client import (
    AsyncGeneratePeopleAlsoAskSeoContentClient,
    GeneratePeopleAlsoAskSeoContentClient,
)
from .generate_product_photo_backgrounds.client import (
    AsyncGenerateProductPhotoBackgroundsClient,
    GenerateProductPhotoBackgroundsClient,
)
from .large_language_models_gpt3.client import AsyncLargeLanguageModelsGpt3Client, LargeLanguageModelsGpt3Client
from .letter_writer.client import AsyncLetterWriterClient, LetterWriterClient
from .lip_syncing.client import AsyncLipSyncingClient, LipSyncingClient
from .lipsync_video_with_any_text.client import AsyncLipsyncVideoWithAnyTextClient, LipsyncVideoWithAnyTextClient
from .misc.client import AsyncMiscClient, MiscClient
from .people_also_ask_answers_from_a_doc.client import (
    AsyncPeopleAlsoAskAnswersFromADocClient,
    PeopleAlsoAskAnswersFromADocClient,
)
from .profile_lookup_gpt3for_ai_personalized_emails.client import (
    AsyncProfileLookupGpt3ForAiPersonalizedEmailsClient,
    ProfileLookupGpt3ForAiPersonalizedEmailsClient,
)
from .render_image_search_results_with_ai.client import (
    AsyncRenderImageSearchResultsWithAiClient,
    RenderImageSearchResultsWithAiClient,
)
from .search_your_docs_with_gpt.client import AsyncSearchYourDocsWithGptClient, SearchYourDocsWithGptClient
from .smart_gpt.client import AsyncSmartGptClient, SmartGptClient
from .speech_recognition_translation.client import (
    AsyncSpeechRecognitionTranslationClient,
    SpeechRecognitionTranslationClient,
)
from .summarize_your_docs_with_gpt.client import AsyncSummarizeYourDocsWithGptClient, SummarizeYourDocsWithGptClient
from .synthetic_data_maker_for_videos_pd_fs.client import (
    AsyncSyntheticDataMakerForVideosPdFsClient,
    SyntheticDataMakerForVideosPdFsClient,
)
from .text_guided_audio_generator.client import AsyncTextGuidedAudioGeneratorClient, TextGuidedAudioGeneratorClient
from .types.bulk_runner_page_response import BulkRunnerPageResponse
from .types.embeddings_page_request_selected_model import EmbeddingsPageRequestSelectedModel
from .types.embeddings_page_response import EmbeddingsPageResponse
from .types.failed_reponse_model_v2 import FailedReponseModelV2
from .types.functions_page_response import FunctionsPageResponse
from .types.generic_error_response import GenericErrorResponse
from .types.http_validation_error import HttpValidationError
from .types.recipe_function import RecipeFunction
from .types.run_settings import RunSettings
from .types.smart_gpt_page_request_selected_model import SmartGptPageRequestSelectedModel
from .types.smart_gpt_page_response import SmartGptPageResponse
from .web_search_gpt3.client import AsyncWebSearchGpt3Client, WebSearchGpt3Client

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class Gooey:
    """
    Use this class to access the different functions within the SDK. You can instantiate any number of clients with different configuration that will propagate to these functions.

    Parameters
    ----------
    base_url : str
        The base url to use for requests from the client.

    authorization : typing.Optional[str]
    timeout : typing.Optional[float]
        The timeout to be used, in seconds, for requests. By default the timeout is 60 seconds, unless a custom httpx client is used, in which case this default is not enforced.

    follow_redirects : typing.Optional[bool]
        Whether the default httpx client follows redirects or not, this is irrelevant if a custom httpx client is passed in.

    httpx_client : typing.Optional[httpx.Client]
        The httpx client to use for making requests, a preconfigured client is used by default, however this is useful should you want to pass in any custom httpx configuration.

    Examples
    --------
    from gooey.client import Gooey

    client = Gooey(
        authorization="YOUR_AUTHORIZATION",
        base_url="https://yourhost.com/path/to/api",
    )
    """

    def __init__(
        self,
        *,
        base_url: str,
        authorization: typing.Optional[str] = None,
        timeout: typing.Optional[float] = None,
        follow_redirects: typing.Optional[bool] = True,
        httpx_client: typing.Optional[httpx.Client] = None
    ):
        _defaulted_timeout = timeout if timeout is not None else 60 if httpx_client is None else None
        self._client_wrapper = SyncClientWrapper(
            base_url=base_url,
            authorization=authorization,
            httpx_client=httpx_client
            if httpx_client is not None
            else httpx.Client(timeout=_defaulted_timeout, follow_redirects=follow_redirects)
            if follow_redirects is not None
            else httpx.Client(timeout=_defaulted_timeout),
            timeout=_defaulted_timeout,
        )
        self.copilot_integrations = CopilotIntegrationsClient(client_wrapper=self._client_wrapper)
        self.copilot_for_your_enterprise = CopilotForYourEnterpriseClient(client_wrapper=self._client_wrapper)
        self.ai_animation_generator = AiAnimationGeneratorClient(client_wrapper=self._client_wrapper)
        self.ai_art_qr_code = AiArtQrCodeClient(client_wrapper=self._client_wrapper)
        self.generate_people_also_ask_seo_content = GeneratePeopleAlsoAskSeoContentClient(
            client_wrapper=self._client_wrapper
        )
        self.create_a_perfect_seo_optimized_title_paragraph = CreateAPerfectSeoOptimizedTitleParagraphClient(
            client_wrapper=self._client_wrapper
        )
        self.web_search_gpt3 = WebSearchGpt3Client(client_wrapper=self._client_wrapper)
        self.profile_lookup_gpt3for_ai_personalized_emails = ProfileLookupGpt3ForAiPersonalizedEmailsClient(
            client_wrapper=self._client_wrapper
        )
        self.bulk_runner = BulkRunnerClient(client_wrapper=self._client_wrapper)
        self.evaluator = EvaluatorClient(client_wrapper=self._client_wrapper)
        self.synthetic_data_maker_for_videos_pd_fs = SyntheticDataMakerForVideosPdFsClient(
            client_wrapper=self._client_wrapper
        )
        self.large_language_models_gpt3 = LargeLanguageModelsGpt3Client(client_wrapper=self._client_wrapper)
        self.search_your_docs_with_gpt = SearchYourDocsWithGptClient(client_wrapper=self._client_wrapper)
        self.smart_gpt = SmartGptClient(client_wrapper=self._client_wrapper)
        self.summarize_your_docs_with_gpt = SummarizeYourDocsWithGptClient(client_wrapper=self._client_wrapper)
        self.functions = FunctionsClient(client_wrapper=self._client_wrapper)
        self.lip_syncing = LipSyncingClient(client_wrapper=self._client_wrapper)
        self.lipsync_video_with_any_text = LipsyncVideoWithAnyTextClient(client_wrapper=self._client_wrapper)
        self.compare_ai_voice_generators = CompareAiVoiceGeneratorsClient(client_wrapper=self._client_wrapper)
        self.speech_recognition_translation = SpeechRecognitionTranslationClient(client_wrapper=self._client_wrapper)
        self.text_guided_audio_generator = TextGuidedAudioGeneratorClient(client_wrapper=self._client_wrapper)
        self.compare_ai_translations = CompareAiTranslationsClient(client_wrapper=self._client_wrapper)
        self.edit_an_image_with_ai_prompt = EditAnImageWithAiPromptClient(client_wrapper=self._client_wrapper)
        self.compare_ai_image_generators = CompareAiImageGeneratorsClient(client_wrapper=self._client_wrapper)
        self.generate_product_photo_backgrounds = GenerateProductPhotoBackgroundsClient(
            client_wrapper=self._client_wrapper
        )
        self.ai_image_with_a_face = AiImageWithAFaceClient(client_wrapper=self._client_wrapper)
        self.ai_generated_photo_from_email_profile_lookup = AiGeneratedPhotoFromEmailProfileLookupClient(
            client_wrapper=self._client_wrapper
        )
        self.render_image_search_results_with_ai = RenderImageSearchResultsWithAiClient(
            client_wrapper=self._client_wrapper
        )
        self.ai_background_changer = AiBackgroundChangerClient(client_wrapper=self._client_wrapper)
        self.compare_ai_image_upscalers = CompareAiImageUpscalersClient(client_wrapper=self._client_wrapper)
        self.chyron_plant_bot = ChyronPlantBotClient(client_wrapper=self._client_wrapper)
        self.letter_writer = LetterWriterClient(client_wrapper=self._client_wrapper)
        self.embeddings = EmbeddingsClient(client_wrapper=self._client_wrapper)
        self.people_also_ask_answers_from_a_doc = PeopleAlsoAskAnswersFromADocClient(
            client_wrapper=self._client_wrapper
        )
        self.misc = MiscClient(client_wrapper=self._client_wrapper)

    def bulk_runner(
        self,
        *,
        documents: typing.Sequence[str],
        run_urls: typing.Sequence[str],
        input_columns: typing.Dict[str, str],
        output_columns: typing.Dict[str, str],
        functions: typing.Optional[typing.Sequence[RecipeFunction]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Any]] = OMIT,
        eval_urls: typing.Optional[typing.Sequence[str]] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None
    ) -> BulkRunnerPageResponse:
        """
        Parameters
        ----------
        documents : typing.Sequence[str]
            Upload or link to a CSV or google sheet that contains your sample input data.
            For example, for Copilot, this would sample questions or for Art QR Code, would would be pairs of image descriptions and URLs.
            Remember to includes header names in your CSV too.

        run_urls : typing.Sequence[str]
            Provide one or more Gooey.AI workflow runs.
            You can add multiple runs from the same recipe (e.g. two versions of your copilot) and we'll run the inputs over both of them.

        input_columns : typing.Dict[str, str]
            For each input field in the Gooey.AI workflow, specify the column in your input data that corresponds to it.

        output_columns : typing.Dict[str, str]
            For each output field in the Gooey.AI workflow, specify the column name that you'd like to use for it in the output data.

        functions : typing.Optional[typing.Sequence[RecipeFunction]]

        variables : typing.Optional[typing.Dict[str, typing.Any]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        eval_urls : typing.Optional[typing.Sequence[str]]
            _(optional)_ Add one or more Gooey.AI Evaluator Workflows to evaluate the results of your runs.

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BulkRunnerPageResponse
            Successful Response

        Examples
        --------
        from gooey.client import Gooey

        client = Gooey(
            authorization="YOUR_AUTHORIZATION",
            base_url="https://yourhost.com/path/to/api",
        )
        client.bulk_runner(
            documents=["documents"],
            run_urls=["run_urls"],
            input_columns={"input_columns": "input_columns"},
            output_columns={"output_columns": "output_columns"},
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v2/bulk-runner/",
            method="POST",
            json={
                "functions": functions,
                "variables": variables,
                "documents": documents,
                "run_urls": run_urls,
                "input_columns": input_columns,
                "output_columns": output_columns,
                "eval_urls": eval_urls,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return pydantic_v1.parse_obj_as(BulkRunnerPageResponse, _response.json())  # type: ignore
            if _response.status_code == 402:
                raise PaymentRequiredError(pydantic_v1.parse_obj_as(typing.Any, _response.json()))  # type: ignore
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    pydantic_v1.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    pydantic_v1.parse_obj_as(GenericErrorResponse, _response.json())  # type: ignore
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    pydantic_v1.parse_obj_as(FailedReponseModelV2, _response.json())  # type: ignore
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def smart_gpt(
        self,
        *,
        input_prompt: str,
        functions: typing.Optional[typing.Sequence[RecipeFunction]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Any]] = OMIT,
        cot_prompt: typing.Optional[str] = OMIT,
        reflexion_prompt: typing.Optional[str] = OMIT,
        dera_prompt: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[SmartGptPageRequestSelectedModel] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None
    ) -> SmartGptPageResponse:
        """
        Parameters
        ----------
        input_prompt : str

        functions : typing.Optional[typing.Sequence[RecipeFunction]]

        variables : typing.Optional[typing.Dict[str, typing.Any]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        cot_prompt : typing.Optional[str]

        reflexion_prompt : typing.Optional[str]

        dera_prompt : typing.Optional[str]

        selected_model : typing.Optional[SmartGptPageRequestSelectedModel]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SmartGptPageResponse
            Successful Response

        Examples
        --------
        from gooey.client import Gooey

        client = Gooey(
            authorization="YOUR_AUTHORIZATION",
            base_url="https://yourhost.com/path/to/api",
        )
        client.smart_gpt(
            input_prompt="input_prompt",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v2/SmartGPT/",
            method="POST",
            json={
                "functions": functions,
                "variables": variables,
                "input_prompt": input_prompt,
                "cot_prompt": cot_prompt,
                "reflexion_prompt": reflexion_prompt,
                "dera_prompt": dera_prompt,
                "selected_model": selected_model,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return pydantic_v1.parse_obj_as(SmartGptPageResponse, _response.json())  # type: ignore
            if _response.status_code == 402:
                raise PaymentRequiredError(pydantic_v1.parse_obj_as(typing.Any, _response.json()))  # type: ignore
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    pydantic_v1.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    pydantic_v1.parse_obj_as(GenericErrorResponse, _response.json())  # type: ignore
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    pydantic_v1.parse_obj_as(FailedReponseModelV2, _response.json())  # type: ignore
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def functions(
        self,
        *,
        code: typing.Optional[str] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Any]] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None
    ) -> FunctionsPageResponse:
        """
        Parameters
        ----------
        code : typing.Optional[str]
            The JS code to be executed.

        variables : typing.Optional[typing.Dict[str, typing.Any]]
            Variables to be used in the code

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        FunctionsPageResponse
            Successful Response

        Examples
        --------
        from gooey.client import Gooey

        client = Gooey(
            authorization="YOUR_AUTHORIZATION",
            base_url="https://yourhost.com/path/to/api",
        )
        client.functions()
        """
        _response = self._client_wrapper.httpx_client.request(
            "v2/functions/",
            method="POST",
            json={"code": code, "variables": variables, "settings": settings},
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return pydantic_v1.parse_obj_as(FunctionsPageResponse, _response.json())  # type: ignore
            if _response.status_code == 402:
                raise PaymentRequiredError(pydantic_v1.parse_obj_as(typing.Any, _response.json()))  # type: ignore
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    pydantic_v1.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    pydantic_v1.parse_obj_as(GenericErrorResponse, _response.json())  # type: ignore
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    pydantic_v1.parse_obj_as(FailedReponseModelV2, _response.json())  # type: ignore
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def embeddings(
        self,
        *,
        texts: typing.Sequence[str],
        functions: typing.Optional[typing.Sequence[RecipeFunction]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Any]] = OMIT,
        selected_model: typing.Optional[EmbeddingsPageRequestSelectedModel] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None
    ) -> EmbeddingsPageResponse:
        """
        Parameters
        ----------
        texts : typing.Sequence[str]

        functions : typing.Optional[typing.Sequence[RecipeFunction]]

        variables : typing.Optional[typing.Dict[str, typing.Any]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        selected_model : typing.Optional[EmbeddingsPageRequestSelectedModel]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EmbeddingsPageResponse
            Successful Response

        Examples
        --------
        from gooey.client import Gooey

        client = Gooey(
            authorization="YOUR_AUTHORIZATION",
            base_url="https://yourhost.com/path/to/api",
        )
        client.embeddings(
            texts=["texts"],
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "v2/embeddings/",
            method="POST",
            json={
                "functions": functions,
                "variables": variables,
                "texts": texts,
                "selected_model": selected_model,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return pydantic_v1.parse_obj_as(EmbeddingsPageResponse, _response.json())  # type: ignore
            if _response.status_code == 402:
                raise PaymentRequiredError(pydantic_v1.parse_obj_as(typing.Any, _response.json()))  # type: ignore
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    pydantic_v1.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    pydantic_v1.parse_obj_as(GenericErrorResponse, _response.json())  # type: ignore
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    pydantic_v1.parse_obj_as(FailedReponseModelV2, _response.json())  # type: ignore
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncGooey:
    """
    Use this class to access the different functions within the SDK. You can instantiate any number of clients with different configuration that will propagate to these functions.

    Parameters
    ----------
    base_url : str
        The base url to use for requests from the client.

    authorization : typing.Optional[str]
    timeout : typing.Optional[float]
        The timeout to be used, in seconds, for requests. By default the timeout is 60 seconds, unless a custom httpx client is used, in which case this default is not enforced.

    follow_redirects : typing.Optional[bool]
        Whether the default httpx client follows redirects or not, this is irrelevant if a custom httpx client is passed in.

    httpx_client : typing.Optional[httpx.AsyncClient]
        The httpx client to use for making requests, a preconfigured client is used by default, however this is useful should you want to pass in any custom httpx configuration.

    Examples
    --------
    from gooey.client import AsyncGooey

    client = AsyncGooey(
        authorization="YOUR_AUTHORIZATION",
        base_url="https://yourhost.com/path/to/api",
    )
    """

    def __init__(
        self,
        *,
        base_url: str,
        authorization: typing.Optional[str] = None,
        timeout: typing.Optional[float] = None,
        follow_redirects: typing.Optional[bool] = True,
        httpx_client: typing.Optional[httpx.AsyncClient] = None
    ):
        _defaulted_timeout = timeout if timeout is not None else 60 if httpx_client is None else None
        self._client_wrapper = AsyncClientWrapper(
            base_url=base_url,
            authorization=authorization,
            httpx_client=httpx_client
            if httpx_client is not None
            else httpx.AsyncClient(timeout=_defaulted_timeout, follow_redirects=follow_redirects)
            if follow_redirects is not None
            else httpx.AsyncClient(timeout=_defaulted_timeout),
            timeout=_defaulted_timeout,
        )
        self.copilot_integrations = AsyncCopilotIntegrationsClient(client_wrapper=self._client_wrapper)
        self.copilot_for_your_enterprise = AsyncCopilotForYourEnterpriseClient(client_wrapper=self._client_wrapper)
        self.ai_animation_generator = AsyncAiAnimationGeneratorClient(client_wrapper=self._client_wrapper)
        self.ai_art_qr_code = AsyncAiArtQrCodeClient(client_wrapper=self._client_wrapper)
        self.generate_people_also_ask_seo_content = AsyncGeneratePeopleAlsoAskSeoContentClient(
            client_wrapper=self._client_wrapper
        )
        self.create_a_perfect_seo_optimized_title_paragraph = AsyncCreateAPerfectSeoOptimizedTitleParagraphClient(
            client_wrapper=self._client_wrapper
        )
        self.web_search_gpt3 = AsyncWebSearchGpt3Client(client_wrapper=self._client_wrapper)
        self.profile_lookup_gpt3for_ai_personalized_emails = AsyncProfileLookupGpt3ForAiPersonalizedEmailsClient(
            client_wrapper=self._client_wrapper
        )
        self.bulk_runner = AsyncBulkRunnerClient(client_wrapper=self._client_wrapper)
        self.evaluator = AsyncEvaluatorClient(client_wrapper=self._client_wrapper)
        self.synthetic_data_maker_for_videos_pd_fs = AsyncSyntheticDataMakerForVideosPdFsClient(
            client_wrapper=self._client_wrapper
        )
        self.large_language_models_gpt3 = AsyncLargeLanguageModelsGpt3Client(client_wrapper=self._client_wrapper)
        self.search_your_docs_with_gpt = AsyncSearchYourDocsWithGptClient(client_wrapper=self._client_wrapper)
        self.smart_gpt = AsyncSmartGptClient(client_wrapper=self._client_wrapper)
        self.summarize_your_docs_with_gpt = AsyncSummarizeYourDocsWithGptClient(client_wrapper=self._client_wrapper)
        self.functions = AsyncFunctionsClient(client_wrapper=self._client_wrapper)
        self.lip_syncing = AsyncLipSyncingClient(client_wrapper=self._client_wrapper)
        self.lipsync_video_with_any_text = AsyncLipsyncVideoWithAnyTextClient(client_wrapper=self._client_wrapper)
        self.compare_ai_voice_generators = AsyncCompareAiVoiceGeneratorsClient(client_wrapper=self._client_wrapper)
        self.speech_recognition_translation = AsyncSpeechRecognitionTranslationClient(
            client_wrapper=self._client_wrapper
        )
        self.text_guided_audio_generator = AsyncTextGuidedAudioGeneratorClient(client_wrapper=self._client_wrapper)
        self.compare_ai_translations = AsyncCompareAiTranslationsClient(client_wrapper=self._client_wrapper)
        self.edit_an_image_with_ai_prompt = AsyncEditAnImageWithAiPromptClient(client_wrapper=self._client_wrapper)
        self.compare_ai_image_generators = AsyncCompareAiImageGeneratorsClient(client_wrapper=self._client_wrapper)
        self.generate_product_photo_backgrounds = AsyncGenerateProductPhotoBackgroundsClient(
            client_wrapper=self._client_wrapper
        )
        self.ai_image_with_a_face = AsyncAiImageWithAFaceClient(client_wrapper=self._client_wrapper)
        self.ai_generated_photo_from_email_profile_lookup = AsyncAiGeneratedPhotoFromEmailProfileLookupClient(
            client_wrapper=self._client_wrapper
        )
        self.render_image_search_results_with_ai = AsyncRenderImageSearchResultsWithAiClient(
            client_wrapper=self._client_wrapper
        )
        self.ai_background_changer = AsyncAiBackgroundChangerClient(client_wrapper=self._client_wrapper)
        self.compare_ai_image_upscalers = AsyncCompareAiImageUpscalersClient(client_wrapper=self._client_wrapper)
        self.chyron_plant_bot = AsyncChyronPlantBotClient(client_wrapper=self._client_wrapper)
        self.letter_writer = AsyncLetterWriterClient(client_wrapper=self._client_wrapper)
        self.embeddings = AsyncEmbeddingsClient(client_wrapper=self._client_wrapper)
        self.people_also_ask_answers_from_a_doc = AsyncPeopleAlsoAskAnswersFromADocClient(
            client_wrapper=self._client_wrapper
        )
        self.misc = AsyncMiscClient(client_wrapper=self._client_wrapper)

    async def bulk_runner(
        self,
        *,
        documents: typing.Sequence[str],
        run_urls: typing.Sequence[str],
        input_columns: typing.Dict[str, str],
        output_columns: typing.Dict[str, str],
        functions: typing.Optional[typing.Sequence[RecipeFunction]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Any]] = OMIT,
        eval_urls: typing.Optional[typing.Sequence[str]] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None
    ) -> BulkRunnerPageResponse:
        """
        Parameters
        ----------
        documents : typing.Sequence[str]
            Upload or link to a CSV or google sheet that contains your sample input data.
            For example, for Copilot, this would sample questions or for Art QR Code, would would be pairs of image descriptions and URLs.
            Remember to includes header names in your CSV too.

        run_urls : typing.Sequence[str]
            Provide one or more Gooey.AI workflow runs.
            You can add multiple runs from the same recipe (e.g. two versions of your copilot) and we'll run the inputs over both of them.

        input_columns : typing.Dict[str, str]
            For each input field in the Gooey.AI workflow, specify the column in your input data that corresponds to it.

        output_columns : typing.Dict[str, str]
            For each output field in the Gooey.AI workflow, specify the column name that you'd like to use for it in the output data.

        functions : typing.Optional[typing.Sequence[RecipeFunction]]

        variables : typing.Optional[typing.Dict[str, typing.Any]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        eval_urls : typing.Optional[typing.Sequence[str]]
            _(optional)_ Add one or more Gooey.AI Evaluator Workflows to evaluate the results of your runs.

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        BulkRunnerPageResponse
            Successful Response

        Examples
        --------
        import asyncio

        from gooey.client import AsyncGooey

        client = AsyncGooey(
            authorization="YOUR_AUTHORIZATION",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.bulk_runner(
                documents=["documents"],
                run_urls=["run_urls"],
                input_columns={"input_columns": "input_columns"},
                output_columns={"output_columns": "output_columns"},
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v2/bulk-runner/",
            method="POST",
            json={
                "functions": functions,
                "variables": variables,
                "documents": documents,
                "run_urls": run_urls,
                "input_columns": input_columns,
                "output_columns": output_columns,
                "eval_urls": eval_urls,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return pydantic_v1.parse_obj_as(BulkRunnerPageResponse, _response.json())  # type: ignore
            if _response.status_code == 402:
                raise PaymentRequiredError(pydantic_v1.parse_obj_as(typing.Any, _response.json()))  # type: ignore
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    pydantic_v1.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    pydantic_v1.parse_obj_as(GenericErrorResponse, _response.json())  # type: ignore
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    pydantic_v1.parse_obj_as(FailedReponseModelV2, _response.json())  # type: ignore
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def smart_gpt(
        self,
        *,
        input_prompt: str,
        functions: typing.Optional[typing.Sequence[RecipeFunction]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Any]] = OMIT,
        cot_prompt: typing.Optional[str] = OMIT,
        reflexion_prompt: typing.Optional[str] = OMIT,
        dera_prompt: typing.Optional[str] = OMIT,
        selected_model: typing.Optional[SmartGptPageRequestSelectedModel] = OMIT,
        avoid_repetition: typing.Optional[bool] = OMIT,
        num_outputs: typing.Optional[int] = OMIT,
        quality: typing.Optional[float] = OMIT,
        max_tokens: typing.Optional[int] = OMIT,
        sampling_temperature: typing.Optional[float] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None
    ) -> SmartGptPageResponse:
        """
        Parameters
        ----------
        input_prompt : str

        functions : typing.Optional[typing.Sequence[RecipeFunction]]

        variables : typing.Optional[typing.Dict[str, typing.Any]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        cot_prompt : typing.Optional[str]

        reflexion_prompt : typing.Optional[str]

        dera_prompt : typing.Optional[str]

        selected_model : typing.Optional[SmartGptPageRequestSelectedModel]

        avoid_repetition : typing.Optional[bool]

        num_outputs : typing.Optional[int]

        quality : typing.Optional[float]

        max_tokens : typing.Optional[int]

        sampling_temperature : typing.Optional[float]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SmartGptPageResponse
            Successful Response

        Examples
        --------
        import asyncio

        from gooey.client import AsyncGooey

        client = AsyncGooey(
            authorization="YOUR_AUTHORIZATION",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.smart_gpt(
                input_prompt="input_prompt",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v2/SmartGPT/",
            method="POST",
            json={
                "functions": functions,
                "variables": variables,
                "input_prompt": input_prompt,
                "cot_prompt": cot_prompt,
                "reflexion_prompt": reflexion_prompt,
                "dera_prompt": dera_prompt,
                "selected_model": selected_model,
                "avoid_repetition": avoid_repetition,
                "num_outputs": num_outputs,
                "quality": quality,
                "max_tokens": max_tokens,
                "sampling_temperature": sampling_temperature,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return pydantic_v1.parse_obj_as(SmartGptPageResponse, _response.json())  # type: ignore
            if _response.status_code == 402:
                raise PaymentRequiredError(pydantic_v1.parse_obj_as(typing.Any, _response.json()))  # type: ignore
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    pydantic_v1.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    pydantic_v1.parse_obj_as(GenericErrorResponse, _response.json())  # type: ignore
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    pydantic_v1.parse_obj_as(FailedReponseModelV2, _response.json())  # type: ignore
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def functions(
        self,
        *,
        code: typing.Optional[str] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Any]] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None
    ) -> FunctionsPageResponse:
        """
        Parameters
        ----------
        code : typing.Optional[str]
            The JS code to be executed.

        variables : typing.Optional[typing.Dict[str, typing.Any]]
            Variables to be used in the code

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        FunctionsPageResponse
            Successful Response

        Examples
        --------
        import asyncio

        from gooey.client import AsyncGooey

        client = AsyncGooey(
            authorization="YOUR_AUTHORIZATION",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.functions()


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v2/functions/",
            method="POST",
            json={"code": code, "variables": variables, "settings": settings},
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return pydantic_v1.parse_obj_as(FunctionsPageResponse, _response.json())  # type: ignore
            if _response.status_code == 402:
                raise PaymentRequiredError(pydantic_v1.parse_obj_as(typing.Any, _response.json()))  # type: ignore
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    pydantic_v1.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    pydantic_v1.parse_obj_as(GenericErrorResponse, _response.json())  # type: ignore
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    pydantic_v1.parse_obj_as(FailedReponseModelV2, _response.json())  # type: ignore
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def embeddings(
        self,
        *,
        texts: typing.Sequence[str],
        functions: typing.Optional[typing.Sequence[RecipeFunction]] = OMIT,
        variables: typing.Optional[typing.Dict[str, typing.Any]] = OMIT,
        selected_model: typing.Optional[EmbeddingsPageRequestSelectedModel] = OMIT,
        settings: typing.Optional[RunSettings] = OMIT,
        request_options: typing.Optional[RequestOptions] = None
    ) -> EmbeddingsPageResponse:
        """
        Parameters
        ----------
        texts : typing.Sequence[str]

        functions : typing.Optional[typing.Sequence[RecipeFunction]]

        variables : typing.Optional[typing.Dict[str, typing.Any]]
            Variables to be used as Jinja prompt templates and in functions as arguments

        selected_model : typing.Optional[EmbeddingsPageRequestSelectedModel]

        settings : typing.Optional[RunSettings]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EmbeddingsPageResponse
            Successful Response

        Examples
        --------
        import asyncio

        from gooey.client import AsyncGooey

        client = AsyncGooey(
            authorization="YOUR_AUTHORIZATION",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.embeddings(
                texts=["texts"],
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "v2/embeddings/",
            method="POST",
            json={
                "functions": functions,
                "variables": variables,
                "texts": texts,
                "selected_model": selected_model,
                "settings": settings,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return pydantic_v1.parse_obj_as(EmbeddingsPageResponse, _response.json())  # type: ignore
            if _response.status_code == 402:
                raise PaymentRequiredError(pydantic_v1.parse_obj_as(typing.Any, _response.json()))  # type: ignore
            if _response.status_code == 422:
                raise UnprocessableEntityError(
                    pydantic_v1.parse_obj_as(HttpValidationError, _response.json())  # type: ignore
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    pydantic_v1.parse_obj_as(GenericErrorResponse, _response.json())  # type: ignore
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    pydantic_v1.parse_obj_as(FailedReponseModelV2, _response.json())  # type: ignore
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
